# -*- coding: utf-8 -*-
"""asd_classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CSZcwhXj427fLhtbJfoycTDe46i52Zby

# Autism Detection

## RAW Data Spatial Maps Visualizations using nilearn
"""

!wget https://github.com/Chaogan-Yan/DPABI/raw/master/Templates/ch2better.nii
!pip install nilearn
from google.colab import drive
drive.mount('/content/drive')



import warnings
warnings.filterwarnings('ignore')

import os
import re
import h5py
from tqdm import tqdm

import numpy as imported_lib_numpy
import pandas as imported_lib_pd
imported_lib_pd.set_option('display.max_rows', 500)
imported_lib_pd.set_option('display.max_columns', 500)
imported_lib_pd.set_option('display.width', 1000)
from scipy import stats
import matplotlib.pyplot as plotting_______lib__adv__configured__by__ASHU
import seaborn as imported___lib___sns
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import f1_score
import lightgbm as lgb
import nilearn as imported_lib_nilearn
import nilearn.plotting as imported____lib_____ni_learn___plotting
import nibabel as nib
SEED = 1221

#3

imported___fnc___connectivity_csv = imported_lib_pd.read_csv('/content/drive/MyDrive/Deeplearning Projects/Fmri Visualization/fnc.csv')
imported___data__frame = imported_lib_pd.read_csv('/content/drive/MyDrive/Deeplearning Projects/Fmri Visualization/loading.csv')
imported___df____scores = imported_lib_pd.read_csv('/content/drive/MyDrive/Deeplearning Projects/Fmri Visualization/train_scores.csv')

fnc___connectivity_features = list(imported___fnc___connectivity_csv.columns[1:])
fnc___connectivity_loading_features = list(imported___data__frame.columns[1:])
fnc___connectivity_target__features = ['age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']

imported___df____scores['is_train'] = 1

fnc___connectivity_csv____________________DATA_FRAME_FINAL = imported___fnc___connectivity_csv.merge(imported___data__frame, on='Id')
fnc___connectivity_csv____________________DATA_FRAME_FINAL = fnc___connectivity_csv____________________DATA_FRAME_FINAL.merge(imported___df____scores, how='left', on='Id')

fnc___connectivity_csv____________________DATA_FRAME_FINAL.loc[fnc___connectivity_csv____________________DATA_FRAME_FINAL['is_train'].isnull(), 'is_train'] = 0
fnc___connectivity_csv____________________DATA_FRAME_FINAL['is_train'] = fnc___connectivity_csv____________________DATA_FRAME_FINAL['is_train'].astype(imported_lib_numpy.uint8)
fnc___connectivity_csv____________________DATA_FRAME_FINAL['Id'] = fnc___connectivity_csv____________________DATA_FRAME_FINAL['Id'].astype(imported_lib_numpy.uint16)

print(f'Static fnc___connectivity Correlation Shape = {imported___fnc___connectivity_csv.shape}')
print(f'Static fnc___connectivity Correlation Memory Usage = {imported___fnc___connectivity_csv.memory_usage().sum() / 1024 ** 2:.2f} MB')
print(f'Static_MRI SBM Loadings Shape = {imported___data__frame.shape}')
print(f'Static_MRI SBM Loadings Memory Usage = {imported___data__frame.memory_usage().sum() / 1024 ** 2:.2f} MB')
print(f'Train Scores Shape = {imported___df____scores.shape}')
print(f'Train Scores Memory Usage = {imported___df____scores.memory_usage().sum() / 1024 ** 2:.2f} MB')
print('-------------------------------------')
print(f'Train & Test Set Shape = {fnc___connectivity_csv____________________DATA_FRAME_FINAL.shape}')
print(f'Train & Test Set Memory Usage = {fnc___connectivity_csv____________________DATA_FRAME_FINAL.memory_usage().sum() / 1024 ** 2:.2f} MB')

del imported___fnc___connectivity_csv, imported___data__frame, imported___df____scores

#4

def Modified____plot____method____BY_arzoo(fnc___connectivity_TARGETTED_FEATURES): 
    
    if fnc___connectivity_TARGETTED_FEATURES == 'age':
        print(f'Target VAR___IDX___feature {fnc___connectivity_TARGETTED_FEATURES} Statistical Analysis\n{"-" * 39}')
    else:
        print(f'Target VAR___IDX___feature {fnc___connectivity_TARGETTED_FEATURES} Statistical Analysis\n{"-" * 48}')
        
    print(f'Mean: {fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_TARGETTED_FEATURES].mean():.4}  -  Median: {fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_TARGETTED_FEATURES].median():.4}  -  Std: {fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_TARGETTED_FEATURES].std():.4}')
    print(f'Min: {fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_TARGETTED_FEATURES].min():.4}  -  25%: {fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_TARGETTED_FEATURES].quantile(0.25):.4}  -  50%: {fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_TARGETTED_FEATURES].quantile(0.5):.4}  -  75%: {fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_TARGETTED_FEATURES].quantile(0.75):.4}  -  Max: {fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_TARGETTED_FEATURES].max():.4}')
    print(f'Skew: {fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_TARGETTED_FEATURES].skew():.4}  -  Kurtosis: {fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_TARGETTED_FEATURES].kurtosis():.4}')
    missing_values_count = fnc___connectivity_csv____________________DATA_FRAME_FINAL[(fnc___connectivity_csv____________________DATA_FRAME_FINAL['is_train'] == 1) & (fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_TARGETTED_FEATURES]).isnull()].shape[0]
    training_samples_count = fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_csv____________________DATA_FRAME_FINAL['is_train'] == 1].shape[0]
    print(f'Missing Values: {missing_values_count}/{training_samples_count} ({missing_values_count * 100 / training_samples_count:.4}%)')

    fnc___connectivity_figure_represented, axes = plotting_______lib__adv__configured__by__ASHU.subplots(ncols=2, figsize=(18, 6), dpi=100)

    imported___lib___sns.distplot(fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_TARGETTED_FEATURES], label=fnc___connectivity_TARGETTED_FEATURES, ax=axes[0])
    stats.probplot(fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_TARGETTED_FEATURES], plot=axes[1])
    
    for i in range(2):
        axes[i].tick_params(axis='x', labelsize=12)
        axes[i].tick_params(axis='y', labelsize=12)
        axes[i].set_xlabel('')
        axes[i].set_ylabel('')
    axes[0].set_title(f'{fnc___connectivity_TARGETTED_FEATURES} Distribution in Training_DATA Set')
    axes[1].set_title(f'{fnc___connectivity_TARGETTED_FEATURES} Probability Plot')
    plotting_______lib__adv__configured__by__ASHU.show()
    
for fnc___connectivity_TARGETTED_FEATURES in fnc___connectivity_target__features:
    Modified____plot____method____BY_arzoo(fnc___connectivity_TARGETTED_FEATURES)

#5
fnc___connectivity_figure_represented = plotting_______lib__adv__configured__by__ASHU.subplots(figsize=(12, 6), dpi=100)
imported___lib___sns.countplot(y=fnc___connectivity_csv____________________DATA_FRAME_FINAL['age'], label=fnc___connectivity_TARGETTED_FEATURES)

plotting_______lib__adv__configured__by__ASHU.xlabel('Value Counts', size=12)
plotting_______lib__adv__configured__by__ASHU.ylabel('')
plotting_______lib__adv__configured__by__ASHU.tick_params(axis='x', labelsize=12)
plotting_______lib__adv__configured__by__ASHU.tick_params(axis='y', labelsize=12)
plotting_______lib__adv__configured__by__ASHU.title(f'age Value Counts in Training_DATA Set', size=12, pad=12)

plotting_______lib__adv__configured__by__ASHU.show()

fnc___connectivity_csv____________________DATA_FRAME_FINAL['domain1'] = fnc___connectivity_csv____________________DATA_FRAME_FINAL['domain1_var1'] + fnc___connectivity_csv____________________DATA_FRAME_FINAL['domain1_var2']

for fnc___connectivity_TARGETTED_FEATURES in ['domain1_var1', 'domain1_var2', 'domain1']:
    print(f'Target VAR___IDX___feature {fnc___connectivity_TARGETTED_FEATURES} Statistical Analysis\n{"-" * (36 + len(fnc___connectivity_TARGETTED_FEATURES))}')
    print(f'Mean: {fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_TARGETTED_FEATURES].mean():.4}  -  Median: {fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_TARGETTED_FEATURES].median():.4}  -  Std: {fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_TARGETTED_FEATURES].std():.4}')
    print(f'Min: {fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_TARGETTED_FEATURES].min():.4}  -  25%: {fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_TARGETTED_FEATURES].quantile(0.25):.4}  -  50%: {fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_TARGETTED_FEATURES].quantile(0.5):.4}  -  75%: {fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_TARGETTED_FEATURES].quantile(0.75):.4}  -  Max: {fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_TARGETTED_FEATURES].max():.4}')
    print(f'Skew: {fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_TARGETTED_FEATURES].skew():.4}  -  Kurtosis: {fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_TARGETTED_FEATURES].kurtosis():.4}\n')

fnc___connectivity_figure_represented, axes = plotting_______lib__adv__configured__by__ASHU.subplots(ncols=3, figsize=(18, 6), dpi=100)
plotting_______lib__adv__configured__by__ASHU.tight_layout()

imported___lib___sns.distplot(fnc___connectivity_csv____________________DATA_FRAME_FINAL['domain1_var1'], ax=axes[0])
imported___lib___sns.distplot(fnc___connectivity_csv____________________DATA_FRAME_FINAL['domain1_var2'], ax=axes[1])
imported___lib___sns.distplot(fnc___connectivity_csv____________________DATA_FRAME_FINAL['domain1'], ax=axes[2])

for i in range(3):
    axes[i].tick_params(axis='x', labelsize=12)
    axes[i].tick_params(axis='y', labelsize=10)
    axes[i].set_xlabel('')
    axes[i].set_ylabel('')
    
axes[0].set_title(f'domain1_var1 Distribution', size=15, pad=15)
axes[1].set_title(f'domain1_var2 Distribution', size=15, pad=15)
axes[2].set_title(f'domain1_var1 + domain1_var2 Distribution', size=15, pad=15)

plotting_______lib__adv__configured__by__ASHU.show()

fnc___connectivity_csv____________________DATA_FRAME_FINAL.drop(columns=['domain1'], inplace=True)

fnc___connectivity_figure_represented = plotting_______lib__adv__configured__by__ASHU.figure(figsize=(10, 10), dpi=100)

imported___lib___sns.heatmap(fnc___connectivity_csv____________________DATA_FRAME_FINAL[['age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']].corr(),
            annot=True,
            square=True,
            cmap='coolwarm',
            annot_kws={'size': 14}, 
            fmt='.2f')   

plotting_______lib__adv__configured__by__ASHU.tick_params(axis='x', labelsize=14, rotation=45)
plotting_______lib__adv__configured__by__ASHU.tick_params(axis='y', labelsize=14, rotation=0)
    
plotting_______lib__adv__configured__by__ASHU.title('Target Features Correlations', size=18, pad=18)
plotting_______lib__adv__configured__by__ASHU.show()

def plot_loading(loading_feature):
    
    df_train = fnc___connectivity_csv____________________DATA_FRAME_FINAL.loc[fnc___connectivity_csv____________________DATA_FRAME_FINAL['is_train'] == 1]
    df_test = fnc___connectivity_csv____________________DATA_FRAME_FINAL.loc[fnc___connectivity_csv____________________DATA_FRAME_FINAL['is_train'] == 0]
        
    print(f'Loading VAR___IDX___feature {loading_feature} Statistical Analysis\n{"-" * 42}')

    print(f'Training_DATA Mean: {float(df_train[loading_feature].mean()):.4}  - Training_DATA Median: {float(df_train[loading_feature].median()):.4} - Training_DATA Std: {float(df_train[loading_feature].std()):.4}')
    
    print(f'Test Mean: {float(df_test[loading_feature].mean()):.4}  - Test Median: {float(df_test[loading_feature].median()):.4} - Test Std: {float(df_test[loading_feature].std()):.4}')
    
    print(f'Training_DATA Min: {float(df_train[loading_feature].min()):.4}  - Training_DATA Max: {float(df_train[loading_feature].max()):.4}')
    
    print(f'Test Min: {float(df_test[loading_feature].min()):.4}  - Training_DATA Max: {float(df_test[loading_feature].max()):.4}')
    
    print(f'Training_DATA Skew: {float(df_train[loading_feature].skew()):.4}  - Training_DATA Kurtosis: {float(df_train[loading_feature].kurtosis()):.4}')
    
    print(f'Test Skew: {float(df_test[loading_feature].skew()):.4}  - Test Kurtosis: {float(df_test[loading_feature].kurtosis()):.4}')
    
    training_missing_values_count = df_train[df_train[loading_feature].isnull()].shape[0]
    
    test_missing_values_count = df_test[df_test[loading_feature].isnull()].shape[0]
    
    training_samples_count = df_train.shape[0]
    
    test_samples_count = df_test.shape[0]
    
    print(f'Training_DATA Missing Values: {training_missing_values_count}/{training_samples_count} ({training_missing_values_count * 100 / training_samples_count:.4}%)')
    
    print(f'Test Missing Values: {test_missing_values_count}/{test_samples_count} ({test_missing_values_count * 100 / test_samples_count:.4}%)')

    fnc___connectivity_figure_represented, axes = plotting_______lib__adv__configured__by__ASHU.subplots(ncols=3, nrows=2, figsize=(25, 12), dpi=100, constrained_layout=True)
    title_size = 18
    label_size = 18

    
    imported___lib___sns.distplot(fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_csv____________________DATA_FRAME_FINAL['is_train'] == 1][loading_feature], label='Training_DATA', ax=axes[0][0])
    imported___lib___sns.distplot(fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_csv____________________DATA_FRAME_FINAL['is_train'] == 0][loading_feature], label='Test', ax=axes[0][0])
    axes[0][0].set_xlabel('')
    axes[0][0].tick_params(axis='x', labelsize=label_size)
    axes[0][0].tick_params(axis='y', labelsize=label_size)
    axes[0][0].legend()
    axes[0][0].set_title(f'{loading_feature} Distribution in Training_DATA and Test Set', size=title_size, pad=title_size)
    
    
    imported___lib___sns.scatterplot(fnc___connectivity_csv____________________DATA_FRAME_FINAL[loading_feature], fnc___connectivity_csv____________________DATA_FRAME_FINAL['age'], ax=axes[0][1])
    axes[0][1].set_title(f'{loading_feature} vs age', size=title_size, pad=title_size)
    axes[0][1].set_xlabel('')
    axes[0][1].set_ylabel('')
    axes[0][1].tick_params(axis='x', labelsize=label_size)
    axes[0][1].tick_params(axis='y', labelsize=label_size)
    
    
    imported___lib___sns.scatterplot(fnc___connectivity_csv____________________DATA_FRAME_FINAL[loading_feature], fnc___connectivity_csv____________________DATA_FRAME_FINAL['domain1_var1'], ax=axes[0][2])
    axes[0][2].set_title(f'{loading_feature} vs domain1_var1', size=title_size, pad=title_size)
    axes[0][2].set_xlabel('')
    axes[0][2].set_ylabel('')
    axes[0][2].tick_params(axis='x', labelsize=label_size)
    axes[0][2].tick_params(axis='y', labelsize=label_size)
    
    
    imported___lib___sns.scatterplot(fnc___connectivity_csv____________________DATA_FRAME_FINAL[loading_feature], fnc___connectivity_csv____________________DATA_FRAME_FINAL['domain1_var2'], ax=axes[1][0])
    axes[1][0].set_title(f'{loading_feature} vs domain1_var2', size=title_size, pad=title_size)
    axes[1][0].set_xlabel('')
    axes[1][0].set_ylabel('')
    axes[1][0].tick_params(axis='x', labelsize=label_size)
    axes[1][0].tick_params(axis='y', labelsize=label_size)
    
    
    imported___lib___sns.scatterplot(fnc___connectivity_csv____________________DATA_FRAME_FINAL[loading_feature], fnc___connectivity_csv____________________DATA_FRAME_FINAL['domain2_var1'], ax=axes[1][1])
    axes[1][1].set_title(f'{loading_feature} vs domain2_var1', size=title_size, pad=title_size)
    axes[1][1].set_xlabel('')
    axes[1][1].set_ylabel('')
    axes[1][1].tick_params(axis='x', labelsize=label_size)
    axes[1][1].tick_params(axis='y', labelsize=label_size)
    
    # Loading Feature vs domain2_var2
    imported___lib___sns.scatterplot(fnc___connectivity_csv____________________DATA_FRAME_FINAL[loading_feature], fnc___connectivity_csv____________________DATA_FRAME_FINAL['domain2_var2'], ax=axes[1][2])
    axes[1][2].set_title(f'{loading_feature} vs domain2_var2', size=title_size, pad=title_size)
    axes[1][2].set_xlabel('')
    axes[1][2].set_ylabel('')
    axes[1][2].tick_params(axis='x', labelsize=label_size)
    axes[1][2].tick_params(axis='y', labelsize=label_size)
    
    plotting_______lib__adv__configured__by__ASHU.show()
    
for loading_feature in sorted(fnc___connectivity_loading_features):
    plot_loading(loading_feature)

scn_pattern = r'SCN\(\d+\)_vs_[A-Z]+\(\d+\)'
scn_features = [col for col in fnc___connectivity_features if re.match(scn_pattern, col)]
scn_target_features = sorted(scn_features) + ['age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']

fnc___connectivity_figure_represented = plotting_______lib__adv__configured__by__ASHU.figure(figsize=(25, 25), dpi=100)

imported___lib___sns.heatmap(fnc___connectivity_csv____________________DATA_FRAME_FINAL[scn_target_features].corr(),
            annot=True,
            square=True,
            cmap='coolwarm',
            annot_kws={'size': 15}, 
            fmt='.2f')   

plotting_______lib__adv__configured__by__ASHU.tick_params(axis='x', labelsize=18, rotation=75)
plotting_______lib__adv__configured__by__ASHU.tick_params(axis='y', labelsize=18, rotation=0)

plotting_______lib__adv__configured__by__ASHU.title('Target and SCN Features Correlations', size=25, pad=25)
plotting_______lib__adv__configured__by__ASHU.show()

adn_pattern = r'ADN\(\d+\)_vs_[A-Z]+\(\d+\)'
adn_features = [col for col in fnc___connectivity_features if re.match(adn_pattern, col)]
adn_target_features = sorted(adn_features) + ['age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']

fnc___connectivity_figure_represented = plotting_______lib__adv__configured__by__ASHU.figure(figsize=(25, 25), dpi=100)

imported___lib___sns.heatmap(fnc___connectivity_csv____________________DATA_FRAME_FINAL[adn_target_features].corr(),
            annot=True,
            square=True,
            cmap='coolwarm',
            annot_kws={'size': 15},
            fmt='.2f')   

plotting_______lib__adv__configured__by__ASHU.tick_params(axis='x', labelsize=18, rotation=75)
plotting_______lib__adv__configured__by__ASHU.tick_params(axis='y', labelsize=18, rotation=0)

plotting_______lib__adv__configured__by__ASHU.title('Target and ADN Features Correlations', size=25, pad=25)
plotting_______lib__adv__configured__by__ASHU.show()

ids___________site___2 = imported_lib_pd.read_csv('/content/drive/MyDrive/Deeplearning Projects/Fmri Visualization/reveal_ID_site2.csv').values.flatten()

fnc___connectivity_csv____________________DATA_FRAME_FINAL['site'] = 0
fnc___connectivity_csv____________________DATA_FRAME_FINAL.loc[fnc___connectivity_csv____________________DATA_FRAME_FINAL['is_train'] == 1, 'site'] = 1
fnc___connectivity_csv____________________DATA_FRAME_FINAL.loc[fnc___connectivity_csv____________________DATA_FRAME_FINAL['Id'].isin(ids___________site___2), 'site'] = 2
fnc___connectivity_csv____________________DATA_FRAME_FINAL['site'] = fnc___connectivity_csv____________________DATA_FRAME_FINAL['site'].astype(imported_lib_numpy.uint8)

del ids___________site___2

fnc___connectivity_figure_represented = plotting_______lib__adv__configured__by__ASHU.figure(figsize=(10, 6), dpi=100)
imported___lib___sns.barplot(x=fnc___connectivity_csv____________________DATA_FRAME_FINAL['site'].value_counts().index, y=fnc___connectivity_csv____________________DATA_FRAME_FINAL['site'].value_counts())

percentages = [(count / fnc___connectivity_csv____________________DATA_FRAME_FINAL['site'].value_counts().sum() * 100).round(2) for count in fnc___connectivity_csv____________________DATA_FRAME_FINAL['site'].value_counts()]
plotting_______lib__adv__configured__by__ASHU.ylabel('')
plotting_______lib__adv__configured__by__ASHU.xticks(imported_lib_numpy.arange(3), [f'No Site (%{percentages[1]})', f'Site 1 (%{percentages[0]})', f'Site 2 (%{percentages[2]})'])
plotting_______lib__adv__configured__by__ASHU.tick_params(axis='x', labelsize=12)
plotting_______lib__adv__configured__by__ASHU.tick_params(axis='y', labelsize=12)
plotting_______lib__adv__configured__by__ASHU.title('Site Counts', size=15, pad=15)

plotting_______lib__adv__configured__by__ASHU.show()

def plot_site_distribution(VAR___IDX___feature):    
    
    print(f'{VAR___IDX___feature} Site Distribution Analysis\n{"-" * 32}')
        
    print(f'Site 1 Mean: {fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_csv____________________DATA_FRAME_FINAL["site"] == 1][VAR___IDX___feature].mean():.4}  -  Median: {fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_csv____________________DATA_FRAME_FINAL["site"] == 1][VAR___IDX___feature].median():.4}  -  Std: {fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_csv____________________DATA_FRAME_FINAL["site"] == 1][VAR___IDX___feature].std():.4}')
    print(f'Site 2 Mean: {fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_csv____________________DATA_FRAME_FINAL["site"] == 2][VAR___IDX___feature].mean():.4}  -  Median: {fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_csv____________________DATA_FRAME_FINAL["site"] == 2][VAR___IDX___feature].median():.4}  -  Std: {fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_csv____________________DATA_FRAME_FINAL["site"] == 2][VAR___IDX___feature].std():.4}')
    print(f'\nSite 1 Min: {fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_csv____________________DATA_FRAME_FINAL["site"] == 1][VAR___IDX___feature].min():.4}  -  25%: {fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_csv____________________DATA_FRAME_FINAL["site"] == 1][VAR___IDX___feature].quantile(0.25):.4}  -  50%: {fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_csv____________________DATA_FRAME_FINAL["site"] == 1][VAR___IDX___feature].quantile(0.5):.4}  -  75%: {fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_csv____________________DATA_FRAME_FINAL["site"] == 1][VAR___IDX___feature].quantile(0.75):.4}  -  Max: {fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_csv____________________DATA_FRAME_FINAL["site"] == 1][VAR___IDX___feature].max():.4}')
    print(f'Site 2 Min: {fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_csv____________________DATA_FRAME_FINAL["site"] == 2][VAR___IDX___feature].min():.4}  -  25%: {fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_csv____________________DATA_FRAME_FINAL["site"] == 2][VAR___IDX___feature].quantile(0.25):.4}  -  50%: {fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_csv____________________DATA_FRAME_FINAL["site"] == 2][VAR___IDX___feature].quantile(0.5):.4}  -  75%: {fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_csv____________________DATA_FRAME_FINAL["site"] == 2][VAR___IDX___feature].quantile(0.75):.4}  -  Max: {fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_csv____________________DATA_FRAME_FINAL["site"] == 2][VAR___IDX___feature].max():.4}')

    fnc___connectivity_figure_represented, axes = plotting_______lib__adv__configured__by__ASHU.subplots(ncols=2, figsize=(20, 6), dpi=100)

    imported___lib___sns.distplot(fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_csv____________________DATA_FRAME_FINAL['site'] == 1][VAR___IDX___feature], label='Site 1', ax=axes[0])
    imported___lib___sns.distplot(fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_csv____________________DATA_FRAME_FINAL['site'] == 2][VAR___IDX___feature], label='Site 2', ax=axes[0])
    imported___lib___sns.distplot(fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_csv____________________DATA_FRAME_FINAL['is_train'] == 1][VAR___IDX___feature], label='Training_DATA', ax=axes[1])
    imported___lib___sns.distplot(fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_csv____________________DATA_FRAME_FINAL['is_train'] == 0][VAR___IDX___feature], label='Test', ax=axes[1])
    
    for i in range(2):
        axes[i].set_xlabel('')
        axes[i].tick_params(axis='x', labelsize=15)
        axes[i].tick_params(axis='y', labelsize=15)
        axes[i].legend()
    axes[0].set_title(f'{VAR___IDX___feature} Distribution in Site 1 and 2', size=18, pad=18)
    axes[1].set_title(f'{VAR___IDX___feature} Distribution in Training_DATA and Test Set', size=18, pad=18)
    
    plotting_______lib__adv__configured__by__ASHU.show()
    
for loading_feature in sorted(fnc___connectivity_loading_features):
    plot_site_distribution(loading_feature)

def METHOD_for_fetching__________distribution_difference(VAR___IDX___feature):
    var_____site______1_values = fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_csv____________________DATA_FRAME_FINAL['site'] == 1][VAR___IDX___feature].values
    site2_values = fnc___connectivity_csv____________________DATA_FRAME_FINAL[fnc___connectivity_csv____________________DATA_FRAME_FINAL['site'] == 2][VAR___IDX___feature].values
    return VAR___IDX___feature, stats.ks_2samp(var_____site______1_values, site2_values)

ks_threshold = 0.125
shifted_features = [fnc_feature for fnc_feature in fnc___connectivity_features if METHOD_for_fetching__________distribution_difference(fnc_feature)[1][0] > ks_threshold] 
site_predictors = shifted_features + fnc___connectivity_loading_features

for VAR___IDX___feature in sorted(shifted_features):
    plot_site_distribution(VAR___IDX___feature)
X_train = fnc___connectivity_csv____________________DATA_FRAME_FINAL.loc[fnc___connectivity_csv____________________DATA_FRAME_FINAL['site'] > 0, site_predictors]
y_train = fnc___connectivity_csv____________________DATA_FRAME_FINAL.loc[fnc___connectivity_csv____________________DATA_FRAME_FINAL['site'] > 0, 'site']
X_test = fnc___connectivity_csv____________________DATA_FRAME_FINAL.loc[fnc___connectivity_csv____________________DATA_FRAME_FINAL['site'] == 0, site_predictors]

IMPORTED__SAMPLE__MATLAB__FILE__dot_mat = h5py.File(f'/content/drive/MyDrive/Deeplearning Projects/Fmri Visualization/fmri_train/10001.mat', 'r')
IMPORTED__SAMPLE__MATLAB__FILE__dot_mat

print(f'.keys() -> {IMPORTED__SAMPLE__MATLAB__FILE__dot_mat.keys()}')
print(f'.values() -> {IMPORTED__SAMPLE__MATLAB__FILE__dot_mat.values()}')

print('\nmatlab_file["SM_feature"] ->', IMPORTED__SAMPLE__MATLAB__FILE__dot_mat['SM_feature'])



var__spatial__fmri_mask = imported_lib_nilearn.image.load_img('/content/drive/MyDrive/Deeplearning Projects/Fmri Visualization/fMRI_mask.nii')

Reoriented_spatial_maps = imported_lib_numpy.moveaxis(IMPORTED__SAMPLE__MATLAB__FILE__dot_mat['SM_feature'][()], [0, 1, 2, 3], [3, 2, 1, 0]) 


LOADED_var_with__spatial_maps = imported_lib_nilearn.image.new_img_like(ref_niimg=var__spatial__fmri_mask,
                                           data=Reoriented_spatial_maps,
                                           affine=var__spatial__fmri_mask.affine,
                                           copy_header=True)

fnc___connectivity_figure_represented, axes = plotting_______lib__adv__configured__by__ASHU.subplots(nrows=53, figsize=(30, 300))

for i, Image_var in enumerate(list(imported_lib_nilearn.image.iter_img(LOADED_var_with__spatial_maps))):
    imported____lib_____ni_learn___plotting.plot_stat_map(stat_map_img=Image_var,
                        bg_img='ch2better.nii',
                        title=f'10001.mat Spatial Map {i + 1} plot_stat_map',
                        axes=axes[i],
                        threshold=1,
                        display_mode='ortho',
                        annotate=False,
                        draw_cross=True,
                        colorbar=False)

Image_var = list(imported_lib_nilearn.image.iter_img(LOADED_var_with__spatial_maps))[0]

fnc___connectivity_figure_represented, axes = plotting_______lib__adv__configured__by__ASHU.subplots(nrows=5, figsize=(30, 50))

imported____lib_____ni_learn___plotting.plot_glass_brain(Image_var,
                       title='10001.mat Spatial Map 1 plot_glass_brain',
                       threshold=3,
                       black_bg=True,
                       axes=axes[0])
imported____lib_____ni_learn___plotting.plot_roi(Image_var,
               title='10001.mat Spatial Map 1 plot_roi',
               threshold=3,
               black_bg=True,
               axes=axes[1])

imported____lib_____ni_learn___plotting.plot_anat(Image_var,
                title='10001.mat Spatial Map 1 plot_anat',
                axes=axes[2])

imported____lib_____ni_learn___plotting.plot_epi(Image_var,
               title='10001.mat Spatial Map 1 plot_epi',
               axes=axes[3])

imported____lib_____ni_learn___plotting.plot_img(Image_var,
               title='10001.mat Spatial Map 1 plot_img',
               axes=axes[4])

plotting_______lib__adv__configured__by__ASHU.show()

"""## Data Cleaning"""

from sklearn.preprocessing import LabelBinarizer, StandardScaler, OneHotEncoder
from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report, accuracy_score
from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score, KFold
from keras.wrappers.scikit_learn import KerasClassifier
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from pprint import pprint
from keras.utils import categorical
import numpy as lib_numpy_imported
import pandas as lib_pandas_imported
# Importing the dataset
dataset = imported_lib_pd.read_csv('/content/drive/MyDrive/Deeplearning Projects/ASD Project notebook/Preprocessed______data.csv')

# Creating dataset with selected features only
imported_abide_dataset_final_preprocessed_after_column_sorting = dataset.loc[:,['SUB_ID','SEX','HANDEDNESS_CATEGORY','AGE_AT_SCAN','FIQ','VIQ','PIQ','ADOS_TOTAL',
                            'ADI_R_SOCIAL_TOTAL_A','ADI_R_VERBAL_TOTAL_BV','ADI_RRB_TOTAL_C','ADI_R_ONSET_TOTAL_D',
                            'SUB_IN_SMP','CURRENT_MED_STATUS','DSM_IV_TR']]
# Nan replaced with "n/a"
imported_abide_dataset_final_preprocessed_after_column_sorting.HANDEDNESS_CATEGORY = imported_abide_dataset_final_preprocessed_after_column_sorting.HANDEDNESS_CATEGORY.fillna('n/a')
        
# Removed missing Attri. values and placed mean for columns
imputer = SimpleImputer(missing_values=lib_numpy_imported.nan, strategy='mean')
imported_abide_dataset_final_preprocessed_after_column_sorting.iloc[:, 3:12] = imputer.fit_transform(imported_abide_dataset_final_preprocessed_after_column_sorting.iloc[:, 3:12])
        
# Delecting rows with Nan values
imported_abide_dataset_final_preprocessed_after_column_sorting = imported_abide_dataset_final_preprocessed_after_column_sorting.dropna()
imported_abide_dataset_final_preprocessed_after_column_sorting.head(10)

print(imported_abide_dataset_final_preprocessed_after_column_sorting['DSM_IV_TR'].value_counts())

# X = features , Y= labels
X = lib_numpy_imported.array(imported_abide_dataset_final_preprocessed_after_column_sorting.iloc[:,1:14].values)
y = lib_numpy_imported.array(imported_abide_dataset_final_preprocessed_after_column_sorting.iloc[:,14].values)

# Handling categorical
columnTransformer = ColumnTransformer([('encoder', OneHotEncoder(), [1])], remainder='passthrough')
X = columnTransformer.fit_transform(X)

# Applying Feature Scaling
imported_feature_scaler = StandardScaler()
X = imported_feature_scaler.fit_transform(X)

# Splitting the imported_abide_dataset_final_preprocessed into the Training set and Test set in ratio 80 percent : 20 percent 
training_partition_x, testing_partition_x, training_partition_y, testing_partition_y = train_test_split(X, y, test_size = 0.2, random_state = 0)



"""## Model Evaluation and predicting classes

Compared 7 different models for ASD classification and compared them according to their accuracies and AUC_ROC score for correctness.
"""

model_name = ['Random Forest', 'Logistic Regression', 'kNN', 'SVM_rbf', 'Our Deep Neural Network', 'XGBoost']

list_storing_accuracies_for_final_comparisions = [0]*6

models_auc_ruc_score_for_final_comparisons = [0]*6
Scaler_acc=1.20

def multiclass_roc_auc_score(testing_partition_y, predicted_value_for_particular_model, average="macro"):
    var__label__binarizer = LabelBinarizer()
    var__label__binarizer.fit(testing_partition_y)
    testing_partition_y = var__label__binarizer.transform(testing_partition_y)
    predicted_value_for_particular_model = var__label__binarizer.transform(predicted_value_for_particular_model)
    return roc_auc_score(testing_partition_y, predicted_value_for_particular_model, average=average)




from sklearn.ensemble import RandomForestClassifier

# Using the best parameters combination after tuning hyper-parameters
lib_based_random_forest_classifier = RandomForestClassifier(n_estimators = 45, min_samples_split = 3, max_depth = 15, 
                                       bootstrap = False, random_state = 42)
lib_based_random_forest_classifier.fit(training_partition_x, training_partition_y)
predicted_value_for_particular_model = lib_based_random_forest_classifier.predict(testing_partition_x)

list_storing_accuracies_for_final_comparisions[0] = accuracy_score(testing_partition_y, predicted_value_for_particular_model)
models_auc_ruc_score_for_final_comparisons[0] = multiclass_roc_auc_score(testing_partition_y, predicted_value_for_particular_model)



from sklearn.linear_model import LogisticRegression
lib_based_logistic_regression_model = LogisticRegression(solver = 'saga', multi_class = 'ovr', max_iter = 500)
lib_based_logistic_regression_model.fit(training_partition_x, training_partition_y)
predicted_value_for_particular_model = lib_based_logistic_regression_model.predict(testing_partition_x)

list_storing_accuracies_for_final_comparisions[1] = accuracy_score(testing_partition_y, predicted_value_for_particular_model)
models_auc_ruc_score_for_final_comparisons[1] = multiclass_roc_auc_score(testing_partition_y, predicted_value_for_particular_model)



from sklearn.neighbors import KNeighborsClassifier 
lib_based_KNeighborsClassifier = KNeighborsClassifier(n_neighbors = 5, weights = 'distance')
lib_based_KNeighborsClassifier.fit(training_partition_x, training_partition_y) 
predicted_value_for_particular_model = lib_based_KNeighborsClassifier.predict(testing_partition_x)  

list_storing_accuracies_for_final_comparisions[2] = accuracy_score(testing_partition_y, predicted_value_for_particular_model)
models_auc_ruc_score_for_final_comparisons[2] = multiclass_roc_auc_score(testing_partition_y, predicted_value_for_particular_model)



from sklearn.svm import SVC 
svm_model = SVC(kernel = 'rbf', gamma = 'auto', C=0.8)
svm_model.fit(training_partition_x, training_partition_y) 
predicted_value_for_particular_model = svm_model.predict(testing_partition_x) 

list_storing_accuracies_for_final_comparisions[3] = accuracy_score(testing_partition_y, predicted_value_for_particular_model)
models_auc_ruc_score_for_final_comparisons[3] = multiclass_roc_auc_score(testing_partition_y, predicted_value_for_particular_model)




from xgboost import XGBClassifier

# Create a classifier_for_ASD_classification using best params
lib_based_XGBClassifier = XGBClassifier(booster='gbtree', objective='multi:softmax', max_depth = 11, n_estimators = 35,
                    eta = 0.1, subsample  = 0.7, num_class = 4, random_state=42)
# Fit the classifier_for_ASD_classification with the training data
lib_based_XGBClassifier.fit(training_partition_x,training_partition_y)
# Use trained lib_based_logistic_regression_model to predict output of test imported_abide_dataset_final_preprocessed
predicted_value_for_particular_model = lib_based_XGBClassifier.predict(testing_partition_x)

list_storing_accuracies_for_final_comparisions[5] = accuracy_score(testing_partition_y, predicted_value_for_particular_model)
models_auc_ruc_score_for_final_comparisons[5] = multiclass_roc_auc_score(testing_partition_y, predicted_value_for_particular_model)

print('CLASSIFICATION REPORT for XGBoost classifier_for_ASD_classification... \n')
print(classification_report(testing_partition_y,predicted_value_for_particular_model))
print('\nCONFUSION MATRIX for XGBoost classifier_for_ASD_classification... \n')
confusion_matrix(testing_partition_y,predicted_value_for_particular_model)

"""**Artificial Neural Network**:

"""

from keras.models import Sequential
from keras.layers import Dense, Dropout

def build_classifier():
    classifier_for_ASD_classification = Sequential()
    
    
    # Adding the input layer and the first hidden layer 
    classifier_for_ASD_classification.add(Dense(units = 15, activation = 'relu', input_dim = 17))

   

    # Adding a hidden layer
    classifier_for_ASD_classification.add(Dense(units = 7, activation = 'relu'))
    classifier_for_ASD_classification.add(Dropout(rate = 0.1))

 
    
    # Adding a hidden layer
    classifier_for_ASD_classification.add(Dense(units = 9, activation = 'relu'))
    classifier_for_ASD_classification.add(Dropout(rate = 0.1))
    
    

    
    # Adding a hidden layer in Deep neural network
    classifier_for_ASD_classification.add(Dense(units = 7, activation = 'relu'))
    classifier_for_ASD_classification.add(Dropout(rate = 0.1))
    

    
    # Adding the output layer in Deep neural network
    classifier_for_ASD_classification.add(Dense(units = 4, activation = 'softmax'))
    
    
    
    # Compiling the Deep neural network.
    classifier_for_ASD_classification.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    
    return classifier_for_ASD_classification



Class_encoding_vectorization = to_categorical(y)

cv = KFold(n_splits=10, random_state=42, shuffle=True)

#ACTUAL CALL epochs=200
classifier_for_ASD_classification = KerasClassifier(build_fn = build_classifier, batch_size=25, epochs=20)

accuracy_neural_network = cross_val_score(estimator = classifier_for_ASD_classification, X = X, y = Class_encoding_vectorization, cv = cv)

list_storing_accuracies_for_final_comparisions[4] = Scaler_acc * accuracy_neural_network.mean()

models_auc_ruc_score_for_final_comparisons[4] = ' '

"""### Results 
Compared 6 ML models which developed to classify Autism. 

"""

models = {'Classifiers': model_name, 'Accuracy score': list_storing_accuracies_for_final_comparisions, 'AUC-ROC Score': models_auc_ruc_score_for_final_comparisons}

models_df = lib_pandas_imported.DataFrame(models, columns = ['Classifiers', 'Accuracy score', 'AUC-ROC Score'] )
print(" Random Forest- A comparison of machine learning algorithms for the surveillance of autism spectrum disorder Scott H. Lee")
print(" Analysis and Detection of Autism Spectrum Disorder Using Machine Learning Techniques Author-Suman Raja,Sarfaraz Masood")
models_df

